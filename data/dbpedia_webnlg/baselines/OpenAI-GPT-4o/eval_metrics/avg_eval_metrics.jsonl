{"id": "global", "type": "global", "avg_precision": "0.52", "avg_recall": "0.39", "avg_f1": "0.43", "avg_onto_conf": "1.00", "avg_sub_halluc": "0.06", "avg_rel_halluc": "0.00", "avg_obj_halluc": "0.13", "onto_list": [{"id": "10_city", "sys": "./data/dbpedia_webnlg/baselines/OpenAI-GPT-4o/llm_responses/ont_10_city_responses.jsonl", "gt": "./data/dbpedia_webnlg/ground_truth/ont_10_city_ground_truth.jsonl", "onto": "./data/dbpedia_webnlg/ontologies/10_city_ontology.json", "output": "./data/dbpedia_webnlg/baselines/OpenAI-GPT-4o/eval_metrics/ont_10_city_eval_results.jsonl"}, {"id": "11_meanoftransportation", "sys": "./data/dbpedia_webnlg/baselines/OpenAI-GPT-4o/llm_responses/ont_11_meanoftransportation_responses.jsonl", "gt": "./data/dbpedia_webnlg/ground_truth/ont_11_meanoftransportation_ground_truth.jsonl", "onto": "./data/dbpedia_webnlg/ontologies/11_meanoftransportation_ontology.json", "output": "./data/dbpedia_webnlg/baselines/OpenAI-GPT-4o/eval_metrics/ont_11_meanoftransportation_eval_results.jsonl"}, {"id": "12_company", "sys": "./data/dbpedia_webnlg/baselines/OpenAI-GPT-4o/llm_responses/ont_12_company_responses.jsonl", "gt": "./data/dbpedia_webnlg/ground_truth/ont_12_company_ground_truth.jsonl", "onto": "./data/dbpedia_webnlg/ontologies/12_company_ontology.json", "output": "./data/dbpedia_webnlg/baselines/OpenAI-GPT-4o/eval_metrics/ont_12_company_eval_results.jsonl"}, {"id": "13_celestialbody", "sys": "./data/dbpedia_webnlg/baselines/OpenAI-GPT-4o/llm_responses/ont_13_celestialbody_responses.jsonl", "gt": "./data/dbpedia_webnlg/ground_truth/ont_13_celestialbody_ground_truth.jsonl", "onto": "./data/dbpedia_webnlg/ontologies/13_celestialbody_ontology.json", "output": "./data/dbpedia_webnlg/baselines/OpenAI-GPT-4o/eval_metrics/ont_13_celestialbody_eval_results.jsonl"}, {"id": "14_musicalwork", "sys": "./data/dbpedia_webnlg/baselines/OpenAI-GPT-4o/llm_responses/ont_14_musicalwork_responses.jsonl", "gt": "./data/dbpedia_webnlg/ground_truth/ont_14_musicalwork_ground_truth.jsonl", "onto": "./data/dbpedia_webnlg/ontologies/14_musicalwork_ontology.json", "output": "./data/dbpedia_webnlg/baselines/OpenAI-GPT-4o/eval_metrics/ont_14_musicalwork_eval_results.jsonl"}, {"id": "15_athlete", "sys": "./data/dbpedia_webnlg/baselines/OpenAI-GPT-4o/llm_responses/ont_15_athlete_responses.jsonl", "gt": "./data/dbpedia_webnlg/ground_truth/ont_15_athlete_ground_truth.jsonl", "onto": "./data/dbpedia_webnlg/ontologies/15_athlete_ontology.json", "output": "./data/dbpedia_webnlg/baselines/OpenAI-GPT-4o/eval_metrics/ont_15_athlete_eval_results.jsonl"}, {"id": "16_university", "sys": "./data/dbpedia_webnlg/baselines/OpenAI-GPT-4o/llm_responses/ont_16_university_responses.jsonl", "gt": "./data/dbpedia_webnlg/ground_truth/ont_16_university_ground_truth.jsonl", "onto": "./data/dbpedia_webnlg/ontologies/16_university_ontology.json", "output": "./data/dbpedia_webnlg/baselines/OpenAI-GPT-4o/eval_metrics/ont_16_university_eval_results.jsonl"}, {"id": "17_sportsteam", "sys": "./data/dbpedia_webnlg/baselines/OpenAI-GPT-4o/llm_responses/ont_17_sportsteam_responses.jsonl", "gt": "./data/dbpedia_webnlg/ground_truth/ont_17_sportsteam_ground_truth.jsonl", "onto": "./data/dbpedia_webnlg/ontologies/17_sportsteam_ontology.json", "output": "./data/dbpedia_webnlg/baselines/OpenAI-GPT-4o/eval_metrics/ont_17_sportsteam_eval_results.jsonl"}, {"id": "18_politician", "sys": "./data/dbpedia_webnlg/baselines/OpenAI-GPT-4o/llm_responses/ont_18_politician_responses.jsonl", "gt": "./data/dbpedia_webnlg/ground_truth/ont_18_politician_ground_truth.jsonl", "onto": "./data/dbpedia_webnlg/ontologies/18_politician_ontology.json", "output": "./data/dbpedia_webnlg/baselines/OpenAI-GPT-4o/eval_metrics/ont_18_politician_eval_results.jsonl"}, {"id": "19_food", "sys": "./data/dbpedia_webnlg/baselines/OpenAI-GPT-4o/llm_responses/ont_19_food_responses.jsonl", "gt": "./data/dbpedia_webnlg/ground_truth/ont_19_food_ground_truth.jsonl", "onto": "./data/dbpedia_webnlg/ontologies/19_food_ontology.json", "output": "./data/dbpedia_webnlg/baselines/OpenAI-GPT-4o/eval_metrics/ont_19_food_eval_results.jsonl"}, {"id": "1_writtenwork", "sys": "./data/dbpedia_webnlg/baselines/OpenAI-GPT-4o/llm_responses/ont_1_writtenwork_responses.jsonl", "gt": "./data/dbpedia_webnlg/ground_truth/ont_1_writtenwork_ground_truth.jsonl", "onto": "./data/dbpedia_webnlg/ontologies/1_writtenwork_ontology.json", "output": "./data/dbpedia_webnlg/baselines/OpenAI-GPT-4o/eval_metrics/ont_1_writtenwork_eval_results.jsonl"}, {"id": "2_airport", "sys": "./data/dbpedia_webnlg/baselines/OpenAI-GPT-4o/llm_responses/ont_2_airport_responses.jsonl", "gt": "./data/dbpedia_webnlg/ground_truth/ont_2_airport_ground_truth.jsonl", "onto": "./data/dbpedia_webnlg/ontologies/2_airport_ontology.json", "output": "./data/dbpedia_webnlg/baselines/OpenAI-GPT-4o/eval_metrics/ont_2_airport_eval_results.jsonl"}, {"id": "3_artist", "sys": "./data/dbpedia_webnlg/baselines/OpenAI-GPT-4o/llm_responses/ont_3_artist_responses.jsonl", "gt": "./data/dbpedia_webnlg/ground_truth/ont_3_artist_ground_truth.jsonl", "onto": "./data/dbpedia_webnlg/ontologies/3_artist_ontology.json", "output": "./data/dbpedia_webnlg/baselines/OpenAI-GPT-4o/eval_metrics/ont_3_artist_eval_results.jsonl"}, {"id": "4_film", "sys": "./data/dbpedia_webnlg/baselines/OpenAI-GPT-4o/llm_responses/ont_4_film_responses.jsonl", "gt": "./data/dbpedia_webnlg/ground_truth/ont_4_film_ground_truth.jsonl", "onto": "./data/dbpedia_webnlg/ontologies/4_film_ontology.json", "output": "./data/dbpedia_webnlg/baselines/OpenAI-GPT-4o/eval_metrics/ont_4_film_eval_results.jsonl"}, {"id": "5_monument", "sys": "./data/dbpedia_webnlg/baselines/OpenAI-GPT-4o/llm_responses/ont_5_monument_responses.jsonl", "gt": "./data/dbpedia_webnlg/ground_truth/ont_5_monument_ground_truth.jsonl", "onto": "./data/dbpedia_webnlg/ontologies/5_monument_ontology.json", "output": "./data/dbpedia_webnlg/baselines/OpenAI-GPT-4o/eval_metrics/ont_5_monument_eval_results.jsonl"}, {"id": "6_comicscharacter", "sys": "./data/dbpedia_webnlg/baselines/OpenAI-GPT-4o/llm_responses/ont_6_comicscharacter_responses.jsonl", "gt": "./data/dbpedia_webnlg/ground_truth/ont_6_comicscharacter_ground_truth.jsonl", "onto": "./data/dbpedia_webnlg/ontologies/6_comicscharacter_ontology.json", "output": "./data/dbpedia_webnlg/baselines/OpenAI-GPT-4o/eval_metrics/ont_6_comicscharacter_eval_results.jsonl"}, {"id": "7_scientist", "sys": "./data/dbpedia_webnlg/baselines/OpenAI-GPT-4o/llm_responses/ont_7_scientist_responses.jsonl", "gt": "./data/dbpedia_webnlg/ground_truth/ont_7_scientist_ground_truth.jsonl", "onto": "./data/dbpedia_webnlg/ontologies/7_scientist_ontology.json", "output": "./data/dbpedia_webnlg/baselines/OpenAI-GPT-4o/eval_metrics/ont_7_scientist_eval_results.jsonl"}, {"id": "8_astronaut", "sys": "./data/dbpedia_webnlg/baselines/OpenAI-GPT-4o/llm_responses/ont_8_astronaut_responses.jsonl", "gt": "./data/dbpedia_webnlg/ground_truth/ont_8_astronaut_ground_truth.jsonl", "onto": "./data/dbpedia_webnlg/ontologies/8_astronaut_ontology.json", "output": "./data/dbpedia_webnlg/baselines/OpenAI-GPT-4o/eval_metrics/ont_8_astronaut_eval_results.jsonl"}, {"id": "9_building", "sys": "./data/dbpedia_webnlg/baselines/OpenAI-GPT-4o/llm_responses/ont_9_building_responses.jsonl", "gt": "./data/dbpedia_webnlg/ground_truth/ont_9_building_ground_truth.jsonl", "onto": "./data/dbpedia_webnlg/ontologies/9_building_ontology.json", "output": "./data/dbpedia_webnlg/baselines/OpenAI-GPT-4o/eval_metrics/ont_9_building_eval_results.jsonl"}]}
{"onto": "1_writtenwork", "type": "all_test_cases", "avg_precision": "0.67", "avg_recall": "0.48", "avg_f1": "0.54", "avg_onto_conf": "0.99", "avg_sub_halluc": "0.07", "avg_rel_halluc": "0.01", "avg_obj_halluc": "0.17"}
{"onto": "10_city", "type": "all_test_cases", "avg_precision": "0.17", "avg_recall": "0.11", "avg_f1": "0.13", "avg_onto_conf": "1.00", "avg_sub_halluc": "0.03", "avg_rel_halluc": "0.00", "avg_obj_halluc": "0.24"}
{"onto": "11_meanoftransportation", "type": "all_test_cases", "avg_precision": "0.39", "avg_recall": "0.25", "avg_f1": "0.29", "avg_onto_conf": "1.00", "avg_sub_halluc": "0.02", "avg_rel_halluc": "0.00", "avg_obj_halluc": "0.19"}
{"onto": "12_company", "type": "all_test_cases", "avg_precision": "0.54", "avg_recall": "0.37", "avg_f1": "0.42", "avg_onto_conf": "1.00", "avg_sub_halluc": "0.09", "avg_rel_halluc": "0.00", "avg_obj_halluc": "0.19"}
{"onto": "13_celestialbody", "type": "all_test_cases", "avg_precision": "0.64", "avg_recall": "0.41", "avg_f1": "0.47", "avg_onto_conf": "1.00", "avg_sub_halluc": "0.00", "avg_rel_halluc": "0.00", "avg_obj_halluc": "0.24"}
{"onto": "14_musicalwork", "type": "all_test_cases", "avg_precision": "0.28", "avg_recall": "0.23", "avg_f1": "0.24", "avg_onto_conf": "1.00", "avg_sub_halluc": "0.31", "avg_rel_halluc": "0.00", "avg_obj_halluc": "0.14"}
{"onto": "15_athlete", "type": "all_test_cases", "avg_precision": "0.62", "avg_recall": "0.42", "avg_f1": "0.48", "avg_onto_conf": "1.00", "avg_sub_halluc": "0.00", "avg_rel_halluc": "0.00", "avg_obj_halluc": "0.10"}
{"onto": "16_university", "type": "all_test_cases", "avg_precision": "0.55", "avg_recall": "0.37", "avg_f1": "0.43", "avg_onto_conf": "1.00", "avg_sub_halluc": "0.00", "avg_rel_halluc": "0.00", "avg_obj_halluc": "0.02"}
{"onto": "17_sportsteam", "type": "all_test_cases", "avg_precision": "0.63", "avg_recall": "0.51", "avg_f1": "0.55", "avg_onto_conf": "1.00", "avg_sub_halluc": "0.02", "avg_rel_halluc": "0.00", "avg_obj_halluc": "0.08"}
{"onto": "18_politician", "type": "all_test_cases", "avg_precision": "0.54", "avg_recall": "0.41", "avg_f1": "0.45", "avg_onto_conf": "1.00", "avg_sub_halluc": "0.02", "avg_rel_halluc": "0.00", "avg_obj_halluc": "0.15"}
{"onto": "19_food", "type": "all_test_cases", "avg_precision": "0.71", "avg_recall": "0.62", "avg_f1": "0.65", "avg_onto_conf": "1.00", "avg_sub_halluc": "0.02", "avg_rel_halluc": "0.00", "avg_obj_halluc": "0.05"}
{"onto": "2_airport", "type": "all_test_cases", "avg_precision": "0.45", "avg_recall": "0.35", "avg_f1": "0.38", "avg_onto_conf": "1.00", "avg_sub_halluc": "0.00", "avg_rel_halluc": "0.00", "avg_obj_halluc": "0.09"}
{"onto": "3_artist", "type": "all_test_cases", "avg_precision": "0.46", "avg_recall": "0.34", "avg_f1": "0.38", "avg_onto_conf": "1.00", "avg_sub_halluc": "0.00", "avg_rel_halluc": "0.00", "avg_obj_halluc": "0.06"}
{"onto": "4_film", "type": "all_test_cases", "avg_precision": "0.43", "avg_recall": "0.36", "avg_f1": "0.38", "avg_onto_conf": "1.00", "avg_sub_halluc": "0.00", "avg_rel_halluc": "0.00", "avg_obj_halluc": "0.06"}
{"onto": "5_monument", "type": "all_test_cases", "avg_precision": "0.26", "avg_recall": "0.22", "avg_f1": "0.23", "avg_onto_conf": "1.00", "avg_sub_halluc": "0.00", "avg_rel_halluc": "0.00", "avg_obj_halluc": "0.04"}
{"onto": "6_comicscharacter", "type": "all_test_cases", "avg_precision": "0.50", "avg_recall": "0.40", "avg_f1": "0.44", "avg_onto_conf": "1.00", "avg_sub_halluc": "0.49", "avg_rel_halluc": "0.00", "avg_obj_halluc": "0.14"}
{"onto": "7_scientist", "type": "all_test_cases", "avg_precision": "0.74", "avg_recall": "0.56", "avg_f1": "0.62", "avg_onto_conf": "0.99", "avg_sub_halluc": "0.00", "avg_rel_halluc": "0.01", "avg_obj_halluc": "0.16"}
{"onto": "8_astronaut", "type": "all_test_cases", "avg_precision": "0.77", "avg_recall": "0.56", "avg_f1": "0.63", "avg_onto_conf": "1.00", "avg_sub_halluc": "0.01", "avg_rel_halluc": "0.00", "avg_obj_halluc": "0.18"}
{"onto": "9_building", "type": "all_test_cases", "avg_precision": "0.57", "avg_recall": "0.45", "avg_f1": "0.49", "avg_onto_conf": "1.00", "avg_sub_halluc": "0.00", "avg_rel_halluc": "0.00", "avg_obj_halluc": "0.09"}
